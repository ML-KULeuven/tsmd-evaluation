Code accompanying the paper *Quantitative Evaluation of Motif Sets in Time Series* by Daan Van Wesenbeeck, Aras Yurtman, Wannes Meert and Hendrik Blockeel (KULeuven). 
This repository (currently) includes code for the proposed evaluation method *PROM*, the existing evaluation metrics *score* and *correctness*, and our benchmark dataset generation procedure which can be used to reconstruct the proposed benchmark (see notebook `generating_the_benchmark.ipynb`).  

<!-- The notebooks folder includes:

- `clustering_classification_datasets.ipynb`: which shows how we clustered classification datasets to find suitable ones for generating TSMD benchmark data. 
- `evaluation_metrics_example.ipynb` : which demonstrates PROM with an example.
- `` : which allows you to generate the proposed benchmark yourself.
- `random_walk_benchmarks.ipynb`: which shows that benchmark based on random-walk data can easily be solved.   -->