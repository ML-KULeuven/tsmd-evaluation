{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6da3d-81d4-48d8-a667-44da33824c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# number time series per benchmark\n",
    "NB_SERIES  = 250\n",
    "# Percentage train\n",
    "TRAIN_SIZE = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314ac0c-7b8f-420c-94b2-25c91169ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g_max(n_classes):\n",
    "    return int(np.floor((n_classes+1)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b71a67-e0cd-4543-956b-25610ed8b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_LENGTH_DATASETS = [\"CharacterTrajectories\", \"SpokenArabicDigits\", \"JapaneseVowels\"]\n",
    "FIX_LENGTH_DATASETS = [\"ArticularyWordRecognition\", \"ERing\", \"Plane\", \"Cricket\", \"Mallat\", \"UWaveGestureLibrary\", \"Symbols\", \"PenDigits\", \"Fungi\", \"NATOPS\", \"ECG5000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71ddeb-28e0-43b9-82bd-0a7c59efbe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacterTrajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1169895/606789555.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=TRAIN_SIZE)).sample(frac=1.0).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2858\n",
      "570\n",
      "2288\n"
     ]
    }
   ],
   "source": [
    "import tsmd_evaluation.benchmark_generation as benchmark_generation\n",
    "\n",
    "columns = {'ds_name': str, 'nclasses': int, 'ndim': int , 'l_min': int, 'l_max': int, 'kappa_max' : int}\n",
    "metadata = pd.DataFrame(columns, index=[])\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "\n",
    "path_to_benchmark = os.path.join(\".\", \"benchmark\")\n",
    "if not os.path.exists(path_to_benchmark):\n",
    "    os.mkdir(path_to_benchmark)\n",
    "\n",
    "\n",
    "def znormalize(ts):\n",
    "    ts = (ts - np.mean(ts, axis=None)) / np.std(ts, axis=None)\n",
    "    return ts\n",
    "\n",
    "for ds_name in FIX_LENGTH_DATASETS + VAR_LENGTH_DATASETS:\n",
    "# for ds_name in [\"Fungi\"]:\n",
    "    np.random.seed(0)    \n",
    "    print(ds_name)\n",
    "    # X, y\n",
    "    X_train, y_train = load_classification(name=ds_name, split='train', load_equal_length=False)\n",
    "    X_test, y_test = load_classification(name=ds_name, split='test', load_equal_length=False)\n",
    "\n",
    "    df_train = benchmark_generation.convert_X_y_to_df(X_train, y_train)\n",
    "    df_test = benchmark_generation.convert_X_y_to_df(X_test, y_test)\n",
    "\n",
    "    # Combine, z-normalize, and resplit\n",
    "    df = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "    df['ts'] = df['ts'].apply(znormalize)\n",
    "    df_train = df.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=TRAIN_SIZE)).sample(frac=1.0).reset_index(drop=True)\n",
    "    df_test  = df.drop(df_train.index).sample(frac=1.0).reset_index(drop=True)\n",
    "        \n",
    "    # Generate tsmd benchmark\n",
    "    classes = df['label'].unique()\n",
    "    n_classes  = len(classes)\n",
    "    g_max = get_g_max(n_classes)\n",
    "    \n",
    "    nb_train = int(TRAIN_SIZE * NB_SERIES) \n",
    "    nb_test  = NB_SERIES - nb_train\n",
    "\n",
    "    benchmark_train = benchmark_generation.generate_tsmd_benchmark_dataset(df_train, nb_train, g_min=1, g_max=g_max)\n",
    "    benchmark_test  = benchmark_generation.generate_tsmd_benchmark_dataset(df_test,  nb_test,  g_min=1, g_max=g_max)\n",
    "    \n",
    "    # Store the benchmark\n",
    "    path_to_benchmark_dataset = os.path.join(path_to_benchmark, ds_name.lower())\n",
    "    if not os.path.exists(path_to_benchmark_dataset):\n",
    "        os.mkdir(path_to_benchmark_dataset) \n",
    "\n",
    "    benchmark_train.to_pickle(os.path.join(path_to_benchmark_dataset, 'validation.pkl'))\n",
    "    benchmark_test.to_pickle(os.path.join(path_to_benchmark_dataset, 'test.pkl'))\n",
    "        \n",
    "    # Store metadata about the instances in the validation set\n",
    "    d = df_train['ts'].iloc[0].shape[1]\n",
    "    \n",
    "    lengths = df_train['length'].to_numpy()\n",
    "    l_min, l_max = np.min(lengths), np.max(lengths)\n",
    "    \n",
    "    new_row = {'ds_name': ds_name.lower(), 'nclasses': n_classes, 'ndim': d , 'l_min': l_min, 'l_max': l_max, 'g_max' : int(np.floor((n_classes+1) / 3.0))}\n",
    "    metadata.loc[len(metadata)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdfe5e-55b8-4e8d-a500-dd4d0399ae76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>nclasses</th>\n",
       "      <th>ndim</th>\n",
       "      <th>l_min</th>\n",
       "      <th>l_max</th>\n",
       "      <th>kappa_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charactertrajectories</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ds_name  nclasses  ndim  l_min  l_max  kappa_max\n",
       "0  charactertrajectories        20     3     63    180          7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata.reset_index(drop=True)\n",
    "metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dok)",
   "language": "python",
   "name": "dok"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
