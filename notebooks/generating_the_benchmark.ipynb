{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e6da3d-81d4-48d8-a667-44da33824c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# number time series per benchmark\n",
    "NB_SERIES  = 250\n",
    "# Percentage train\n",
    "TRAIN_SIZE = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7314ac0c-7b8f-420c-94b2-25c91169ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g_max(n_classes):\n",
    "    return int(np.floor((n_classes+1)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b71a67-e0cd-4543-956b-25610ed8b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_LENGTH_DATASETS = [\"CharacterTrajectories\", \"SpokenArabicDigits\", \"JapaneseVowels\"]\n",
    "FIX_LENGTH_DATASETS = [\"ArticularyWordRecognition\", \"ERing\", \"Plane\", \"Cricket\", \"Mallat\", \"UWaveGestureLibrary\", \"Symbols\", \"PenDigits\", \"Fungi\", \"NATOPS\", \"ECG5000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb71ddeb-28e0-43b9-82bd-0a7c59efbe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticularyWordRecognition\n",
      "ERing\n",
      "Plane\n",
      "Cricket\n",
      "Mallat\n",
      "UWaveGestureLibrary\n",
      "Symbols\n",
      "PenDigits\n",
      "Fungi\n",
      "NATOPS\n",
      "ECG5000\n",
      "CharacterTrajectories\n",
      "SpokenArabicDigits\n",
      "JapaneseVowels\n"
     ]
    }
   ],
   "source": [
    "import tsmd_evaluation.benchmark_generation as benchmark_generation\n",
    "\n",
    "columns = {'ds_name': str, 'nclasses': int, 'ndim': int , 'l_min': int, 'l_max': int, 'kappa_max' : int}\n",
    "metadata = pd.DataFrame(columns, index=[])\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "\n",
    "path_to_benchmark = os.path.join(\".\", \"benchmark\")\n",
    "if not os.path.exists(path_to_benchmark):\n",
    "    os.mkdir(path_to_benchmark)\n",
    "\n",
    "\n",
    "def znormalize(ts):\n",
    "    ts = (ts - np.mean(ts, axis=None)) / np.std(ts, axis=None)\n",
    "    return ts\n",
    "\n",
    "for ds_name in FIX_LENGTH_DATASETS + VAR_LENGTH_DATASETS:\n",
    "# for ds_name in [\"Fungi\"]:\n",
    "    np.random.seed(0)    \n",
    "    print(ds_name)\n",
    "    # X, y\n",
    "    X_train, y_train = load_classification(name=ds_name, split='train', load_equal_length=False)\n",
    "    X_test, y_test = load_classification(name=ds_name, split='test', load_equal_length=False)\n",
    "\n",
    "    df_train = benchmark_generation.convert_X_y_to_df(X_train, y_train)\n",
    "    df_test = benchmark_generation.convert_X_y_to_df(X_test, y_test)\n",
    "\n",
    "    # Combine, z-normalize, and resplit\n",
    "    df = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "    df['ts'] = df['ts'].apply(znormalize)\n",
    "    df_train = df.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=TRAIN_SIZE)).sample(frac=1.0).reset_index(drop=True)\n",
    "    df_test  = df.drop(df_train.index).sample(frac=1.0).reset_index(drop=True)\n",
    "        \n",
    "    # Generate tsmd benchmark\n",
    "    classes = df['label'].unique()\n",
    "    n_classes  = len(classes)\n",
    "    g_max = get_g_max(n_classes)\n",
    "    \n",
    "    nb_train = int(TRAIN_SIZE * NB_SERIES) \n",
    "    nb_test  = NB_SERIES - nb_train\n",
    "\n",
    "    benchmark_train = benchmark_generation.generate_tsmd_benchmark_dataset(df_train, nb_train, g_min=1, g_max=g_max)\n",
    "    benchmark_test  = benchmark_generation.generate_tsmd_benchmark_dataset(df_test,  nb_test,  g_min=1, g_max=g_max)\n",
    "    \n",
    "    # Store the benchmark\n",
    "    path_to_benchmark_dataset = os.path.join(path_to_benchmark, ds_name.lower())\n",
    "    if not os.path.exists(path_to_benchmark_dataset):\n",
    "        os.mkdir(path_to_benchmark_dataset) \n",
    "\n",
    "    benchmark_train.to_pickle(os.path.join(path_to_benchmark_dataset, 'validation.pkl'))\n",
    "    benchmark_test.to_pickle(os.path.join(path_to_benchmark_dataset, 'test.pkl'))\n",
    "        \n",
    "    # Store metadata about the instances in the validation set\n",
    "    d = df_train['ts'].iloc[0].shape[1]\n",
    "    \n",
    "    lengths = df_train['length'].to_numpy()\n",
    "    l_min, l_max = np.min(lengths), np.max(lengths)\n",
    "    \n",
    "    new_row = {'ds_name': ds_name.lower(), 'nclasses': n_classes, 'ndim': d , 'l_min': l_min, 'l_max': l_max, 'kappa_max' : int(np.floor((n_classes+1) / 3.0))}\n",
    "    metadata.loc[len(metadata)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cdfe5e-55b8-4e8d-a500-dd4d0399ae76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>nclasses</th>\n",
       "      <th>ndim</th>\n",
       "      <th>l_min</th>\n",
       "      <th>l_max</th>\n",
       "      <th>kappa_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>articularywordrecognition</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ering</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cricket</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1197</td>\n",
       "      <td>1197</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mallat</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uwavegesturelibrary</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>symbols</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pendigits</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fungi</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>natops</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ecg5000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>charactertrajectories</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spokenarabicdigits</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>japanesevowels</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds_name  nclasses  ndim  l_min  l_max  kappa_max\n",
       "0   articularywordrecognition        25     9    144    144          8\n",
       "1                       ering         6     4     65     65          2\n",
       "2                       plane         7     1    144    144          2\n",
       "3                     cricket        12     6   1197   1197          4\n",
       "4                      mallat         8     1   1024   1024          3\n",
       "5         uwavegesturelibrary         8     3    315    315          3\n",
       "6                     symbols         6     1    398    398          2\n",
       "7                   pendigits        10     2      8      8          3\n",
       "8                       fungi        18     1    201    201          6\n",
       "9                      natops         6    24     51     51          2\n",
       "10                    ecg5000         5     1    140    140          2\n",
       "11      charactertrajectories        20     3     63    180          7\n",
       "12         spokenarabicdigits        10    13      4     87          3\n",
       "13             japanesevowels         9    12      7     24          3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata.reset_index(drop=True)\n",
    "metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
